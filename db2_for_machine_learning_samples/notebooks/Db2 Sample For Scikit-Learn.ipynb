{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright IBM All Rights Reserved.\n",
    "#### SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Db2 Sample For Scikit-Learn\n",
    "\n",
    "In this code sample, we will show how to use the Db2 Python driver to import data from our Db2 database. Then, we will use that data to create a machine learning model with scikit-learn.\n",
    "\n",
    "Many wine connoisseurs love to taste different wines from all over the world. Mostly importantly, they want to know how the quality differs between each wine based on the ingredients. Some of them also want to be able to predict the quality before even tasting it. In this notebook, we will be using a dataset that has collected certain attributes of many wine bottles that determines the quality of the wine. Using this dataset, we will help our wine connoisseurs predict the quality of wine.\n",
    "\n",
    "This notebook will demonstrate how to use Db2 as a data source for creating machine learning models.\n",
    "\n",
    "Prerequisites:\n",
    "1. Python 3.6 and above\n",
    "2. Db2 on Cloud instance (using free-tier option)\n",
    "3. Data already loaded in your Db2 instance\n",
    "4. Have Db2 connection credentials on hand\n",
    "\n",
    "We will be importing two libraries- `ibm_db` and `ibm_dbi`. `ibm_db` is a library with low-level functions that will directly connect to our db2 database. To make things easier for you, we will be using `ibm-dbi`, which communicates with `ibm-db` and gives us an easy interface to interact with our data and import our data as a pandas dataframe. \n",
    "\n",
    "For this example, we will be using the [winequality-red dataset](../data/winequality-red.csv), which we have loaded into our Db2 instance.\n",
    "\n",
    "NOTE: Running this notebook within a docker container. If `!easy_install ibm_db` doesn't work on your normally on jupter notebook, you may need to also run this notebook within a docker container as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data\n",
    "Let's first install and import all the libraries needed for this notebook. Most important we will be installing and importing the db2 python driver `ibm_db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn\n",
    "!easy_install ibm_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# The two python ibm db2 drivers we need\n",
    "import ibm_db\n",
    "import ibm_db_dbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import our data from our data source using the python db2 driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace only <> credentials\n",
    "dsn = \"DRIVER={{IBM DB2 ODBC DRIVER}};\" + \\\n",
    "      \"DATABASE=<DATABASE NAME>;\" + \\\n",
    "      \"HOSTNAME=<HOSTNMAE>;\" + \\\n",
    "      \"PORT=50000;\" + \\\n",
    "      \"PROTOCOL=TCPIP;\" + \\\n",
    "      \"UID=<USERNAME>;\" + \\\n",
    "      \"PWD=<PWD>;\"\n",
    "hdbc  = ibm_db.connect(dsn, \"\", \"\")\n",
    "hdbi = ibm_db_dbi.Connection(hdbc)\n",
    "\n",
    "sql = 'SELECT * FROM <SCHEMA NAME>.<TABLE NAME>'\n",
    "\n",
    "wine = pandas.read_sql(sql,hdbi)\n",
    "#wine = pd.read_csv('../data/winequality-red.csv', sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we are going to try and explore our data inorder to gain insight. We hope to be able to make some assumptions of our data before we start modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum price of the data\n",
    "minimum_price = np.amin(wine['quality'])\n",
    "\n",
    "# Maximum price of the data\n",
    "maximum_price = np.amax(wine['quality'])\n",
    "\n",
    "# Mean price of the data\n",
    "mean_price = np.mean(wine['quality'])\n",
    "\n",
    "# Median price of the data\n",
    "median_price = np.median(wine['quality'])\n",
    "\n",
    "# Standard deviation of prices of the data\n",
    "std_price = np.std(wine['quality'])\n",
    "\n",
    "# Show the calculated statistics\n",
    "print(\"Statistics for housing dataset:\\n\")\n",
    "print(\"Minimum quality: {}\".format(minimum_price)) \n",
    "print(\"Maximum quality: {}\".format(maximum_price))\n",
    "print(\"Mean quality: {}\".format(mean_price))\n",
    "print(\"Median quality {}\".format(median_price))\n",
    "print(\"Standard deviation of quality: {}\".format(std_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = wine.corr()\n",
    "corr_matrix[\"quality\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.hist(bins=50, figsize=(30,25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = wine.boxplot(column=['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned and explored our data. We are ready to build our model that will predict the attribute `quality`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_value = wine['quality']\n",
    "wine_attributes = wine.drop(['quality'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Let us scale our data first \n",
    "sc = StandardScaler()\n",
    "wine_attributes = sc.fit_transform(wine_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to our data\n",
    "pca = PCA(n_components=8)\n",
    "x_pca = pca.fit_transform(wine_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split our data into train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split our data into test and train data\n",
    "x_train, x_test, y_train, y_test = train_test_split( wine_attributes,wine_value, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Logistic Regression to model our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train our model\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Predict using our trained model and our test data\n",
    "lr_predict = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix and accuracy score\n",
    "lr_conf_matrix = confusion_matrix(y_test, lr_predict)\n",
    "lr_acc_score = accuracy_score(y_test, lr_predict)\n",
    "print(lr_conf_matrix)\n",
    "print(lr_acc_score*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
