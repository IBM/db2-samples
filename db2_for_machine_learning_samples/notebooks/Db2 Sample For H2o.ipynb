{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright IBM All Rights Reserved.\n",
    "#### SPDX-License-Identifier: Apache-2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Db2 Sample For H20\n",
    "\n",
    "In this code sample, we will show how to use the Db2 Python driver to import data from our Db2 database. Then, we will use that data to create a machine learning model with H20.\n",
    "\n",
    "Many wine connoisseurs love to taste different wines from all over the world. Mostly importantly, they want to know how the quality differs between each wine based on the ingredients. Some of them also want to be able to predict the quality before even tasting it. In this notebook, we will be using a dataset that has collected certain attributes of many wine bottles that determines the quality of the wine. Using this dataset, we will help our wine connoisseurs predict the quality of wine.\n",
    "\n",
    "This notebook will demonstrate how to use Db2 as a data source for creating machine learning models.\n",
    "\n",
    "Prerequisites:\n",
    "1. Python 3.6 and above\n",
    "2. Db2 on Cloud instance (using free-tier option)\n",
    "3. Data already loaded in your Db2 instance\n",
    "4. Have Db2 connection credentials on hand\n",
    "\n",
    "We will be importing two libraries- `ibm_db` and `ibm_dbi`. `ibm_db` is a library with low-level functions that will directly connect to our db2 database. To make things easier for you, we will be using `ibm-dbi`, which communicates with `ibm-db` and gives us an easy interface to interact with our data and import our data as a pandas dataframe. \n",
    "\n",
    "For this example, we will be using the [winequality-red dataset](../data/winequality-red.csv), which we have loaded into our Db2 instance.\n",
    "\n",
    "NOTE: Running this notebook within a docker container. If `!easy_install ibm_db` doesn't work on your normally on jupter notebook, you may need to also run this notebook within a docker container as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data\n",
    "Let's first install and import all the libraries needed for this notebook. Most important we will be installing and importing the db2 python driver `ibm_db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h2o\n",
    "!easy_install ibm_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# The two python ibm db2 drivers we need\n",
    "import ibm_db\n",
    "import ibm_db_dbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace only <> credentials\n",
    "dsn = \"DRIVER={{IBM DB2 ODBC DRIVER}};\" + \\\n",
    "      \"DATABASE=<DATABASE NAME>;\" + \\\n",
    "      \"HOSTNAME=<HOSTNMAE>;\" + \\\n",
    "      \"PORT=50000;\" + \\\n",
    "      \"PROTOCOL=TCPIP;\" + \\\n",
    "      \"UID=<USERNAME>;\" + \\\n",
    "      \"PWD=<PWD>;\"\n",
    "hdbc  = ibm_db.connect(dsn, \"\", \"\")\n",
    "hdbi = ibm_db_dbi.Connection(hdbc)\n",
    "\n",
    "sql = 'SELECT * FROM <SCHEMA NAME>.<TABLE NAME>'\n",
    "\n",
    "wine = pd.read_sql(sql,hdbi)\n",
    "#wine = pd.read_csv('../data/winequality-red.csv', sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what our data looks like\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we are going to try and explore our data inorder to gain insight. We hope to be able to make some assumptions of our data before we start modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum price of the data\n",
    "minimum_price = np.amin(wine['quality'])\n",
    "\n",
    "# Maximum price of the data\n",
    "maximum_price = np.amax(wine['quality'])\n",
    "\n",
    "# Mean price of the data\n",
    "mean_price = np.mean(wine['quality'])\n",
    "\n",
    "# Median price of the data\n",
    "median_price = np.median(wine['quality'])\n",
    "\n",
    "# Standard deviation of prices of the data\n",
    "std_price = np.std(wine['quality'])\n",
    "\n",
    "# Show the calculated statistics\n",
    "print(\"Statistics for housing dataset:\\n\")\n",
    "print(\"Minimum quality: {}\".format(minimum_price)) \n",
    "print(\"Maximum quality: {}\".format(maximum_price))\n",
    "print(\"Mean quality: {}\".format(mean_price))\n",
    "print(\"Median quality {}\".format(median_price))\n",
    "print(\"Standard deviation of quality: {}\".format(std_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = wine.corr()\n",
    "corr_matrix[\"quality\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.hist(bins=50, figsize=(30,25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = wine.boxplot(column=['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Machine Learning Model\n",
    "\n",
    "Now that we have cleaned and explored our data. We are ready to build our model that will predict the attribute `Class`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "\n",
    "# Create an H2o session\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a Pandas Data Frame to H2o Frame\n",
    "wine_data = h2o.H2OFrame(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the data is no corrupted during conversion\n",
    "wine_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into tran and test data\n",
    "wine_split = wine_data.split_frame(ratios = [0.8], seed = 1234)\n",
    "wine_train = wine_split[0] # using 80% for training\n",
    "wine_test = wine_split[1] #rest 20% for testing\n",
    "\n",
    "# Verify shape of data sets\n",
    "print(wine_train.shape, wine_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We to define the predictors for this model\n",
    "predictors = list(wine_data.columns) \n",
    "\n",
    "# Since we need to predict quality, let's take that out \n",
    "predictors.remove('quality')  \n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function for GLM\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "\n",
    "# Set up GLM for regression\n",
    "glm = H2OGeneralizedLinearEstimator(family = 'gaussian', model_id = 'glm_default')\n",
    "\n",
    "# Use .train() to build the model\n",
    "glm.train(x = predictors, y = 'quality', training_frame = wine_train)\n",
    "\n",
    "print(glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.model_performance(wine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = glm.predict(wine_test)\n",
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. H2o Auto ML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will walk through how to use H2o AutoML Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# Here AutoML will run for 20 base models for 100 seconds.\n",
    "aml = H2OAutoML(max_models = 20, max_runtime_secs=100, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training our model\n",
    "aml.train(x=predictors, y='quality', training_frame=wine_train, validation_frame=wine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us look at the automl leaderboard.\n",
    "print(aml.leaderboard)\n",
    "\n",
    "#The leaderboard displays the top 10 models built by AutoML with their parameters. \n",
    "#The best model is placed on the top is a Stacked Ensemble."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
